# =============================================================================
# CONFIGURACIÃ“N PARA INSTALACIÃ“N DE CONTROLADORES DE INGRESS
# =============================================================================
# Este archivo contiene todas las variables necesarias para instalar
# AWS Load Balancer Controller y NGINX Ingress Controller en Amazon EKS
#
# INSTRUCCIONES:
# 1. Edita los valores segÃºn tu entorno
# 2. Las variables marcadas como OBLIGATORIAS deben tener valores
# 3. Las variables OPCIONALES pueden dejarse vacÃ­as para usar valores por defecto
# =============================================================================

# -----------------------------------------------------------------------------
# ğŸ¯ SWITCHES DE INSTALACIÃ“N (CONFIGURAR PRIMERO)
# -----------------------------------------------------------------------------

# Instalar AWS Load Balancer Controller
# VALORES: "true" o "false"
export INSTALL_AWS_LB_CONTROLLER="true"

# Instalar NGINX Ingress Controller  
# VALORES: "true" o "false"
export INSTALL_NGINX_CONTROLLER="true"

# Instalar NodeClass y NodePool (EKS Auto Mode)
# VALORES: "true" o "false"
export INSTALL_NODECLASS_NODEPOOL="true"

# -----------------------------------------------------------------------------
# ğŸ—ï¸ CONFIGURACIÃ“N DE NODECLASS Y NODEPOOL (EKS AUTO MODE)
# -----------------------------------------------------------------------------

# Nombre del NodeClass
#export NODECLASS_NAME="ban-xrs-karpenter-eks-cluster-nodeclass"
export NODECLASS_NAME="xrs-nodeclass"

# Nombre del NodePool
#export NODEPOOL_NAME="ban-xrs-karpenter-eks-cluster-nodepool"
export NODEPOOL_NAME="xrs-nodepool"

# Rol IAM para los nodos (sin arn, solo el nombre)
#export NODE_ROLE_NAME="ban-xrs-karpenter-eks-cluster-poc-auto-mode-node-role"
export NODE_ROLE_NAME="ban-xrs-karpenter-eks-cluster-poc-auto-mode-node-role"

# Tag para seleccionar Security Groups de nodos
export SECURITY_GROUP_TAG_VALUE="1"

# TamaÃ±o del almacenamiento efÃ­mero
export EPHEMERAL_STORAGE_SIZE="20Gi"

# Etiqueta del equipo de facturaciÃ³n
export BILLING_TEAM="CloudOps"

# Nombre para las instancias EC2
#export INSTANCE_NAME="ban-xrs-ic-ec2-worker-dev"
export INSTANCE_NAME="xrs-Karpenter"

# Familias de instancia especÃ­ficas (separadas por comas)
export INSTANCE_FAMILIES="c6i,c6a,c7i,c7a,m6i,m6a,m7i,m7a,r6i,r6a,r7i,r7a,t3"

# Zonas de disponibilidad (separadas por comas)
export AVAILABILITY_ZONES="us-east-1a,us-east-1b"

# Arquitectura
export NODE_ARCHITECTURE="amd64"

# Sistema operativo (linux o windows)
export NODE_OS="linux"

# Tipo de capacidad (on-demand o spot)
export CAPACITY_TYPE="on-demand"

# Etiqueta personalizada para identificar nodos de Karpenter
export CUSTOM_LABEL_KEY="lanzamiento"
export CUSTOM_LABEL_VALUE="karpenter"

# PolÃ­tica de consolidaciÃ³n de nodos
# Controla cÃ³mo Karpenter optimiza el uso de recursos consolidando workloads
# - WhenEmpty: Solo consolida nodos completamente vacÃ­os (mÃ¡s conservador)
# - WhenEmptyOrUnderutilized: Consolida nodos vacÃ­os o con baja utilizaciÃ³n (recomendado)
#
# Recomendaciones por Ambiente:
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ Ambiente â”‚ PolÃ­tica    â”‚ Ahorro Costo     â”‚ Riesgo Disrup.  â”‚
# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
# â”‚ DEV      â”‚ WhenEmptyOrUnderutilized â”‚ 40-60%           â”‚ Bajo            â”‚
# â”‚ STG      â”‚ WhenEmptyOrUnderutilized â”‚ 30-50%           â”‚ Medio           â”‚
# â”‚ UAT      â”‚ WhenEmpty                â”‚ 20-30%           â”‚ Bajo            â”‚
# â”‚ PRD      â”‚ WhenEmpty                â”‚ 15-25%           â”‚ MÃ­nimo          â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
export CONSOLIDATION_POLICY="WhenEmptyOrUnderutilized"

# Tiempo de espera antes de consolidar nodos
# Tiempo que espera Karpenter antes de iniciar la consolidaciÃ³n
# Valores: 30s mÃ­nimo, 30s por defecto, sin mÃ¡ximo
# - Menor tiempo: ConsolidaciÃ³n mÃ¡s agresiva, mayor ahorro
# - Mayor tiempo: ConsolidaciÃ³n mÃ¡s conservadora, menor disrupciÃ³n
#
# Recomendaciones por Ambiente:
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ Ambiente â”‚ Tiempo      â”‚ Ahorro Costo     â”‚ Riesgo Disrup.  â”‚
# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
# â”‚ DEV      â”‚ 30s         â”‚ MÃ¡ximo           â”‚ Alto            â”‚
# â”‚ STG      â”‚ 2m          â”‚ Alto             â”‚ Medio           â”‚
# â”‚ UAT      â”‚ 5m          â”‚ Medio            â”‚ Bajo            â”‚
# â”‚ PRD      â”‚ 10m         â”‚ Conservador      â”‚ MÃ­nimo          â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
export CONSOLIDATE_AFTER="30s"

# Presupuesto de disrupciÃ³n (Disruption Budget)
# Controla cuÃ¡ntos nodos pueden ser interrumpidos simultÃ¡neamente durante
# operaciones de Karpenter (consolidaciÃ³n, actualizaciones, scaling)
# Protege la disponibilidad de aplicaciones limitando disrupciones concurrentes
#
# Formatos soportados:
# - Porcentaje: "10%", "25%", "50%" (porcentaje del total de nodos)
# - Absoluto: "1", "3", "5" (nÃºmero fijo de nodos)
# - VacÃ­o: "" (usa default del 10%)
#
# Recomendaciones por Ambiente:
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ Ambiente â”‚ Budget      â”‚ Disponibilidad   â”‚ Velocidad Cambioâ”‚
# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
# â”‚ DEV      â”‚ 50%         â”‚ Media            â”‚ RÃ¡pida          â”‚
# â”‚ STG      â”‚ 25%         â”‚ Alta             â”‚ Media           â”‚
# â”‚ UAT      â”‚ 10%         â”‚ Muy Alta         â”‚ Lenta           â”‚
# â”‚ PRD      â”‚ 5% o 1      â”‚ MÃ¡xima           â”‚ Muy Lenta       â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# NOTA: Si tienes mÃºltiples budgets, Karpenter usa el MÃS RESTRICTIVO
export DISRUPTION_BUDGET="50%"

# LÃ­mites del NodePool
# Controla el mÃ¡ximo de recursos que puede usar este NodePool
# Estos lÃ­mites previenen el crecimiento descontrolado y controlan costos
# IMPORTANTE: Ajustar segÃºn el ambiente y presupuesto
#
# Ejemplos de capacidad por tipo de instancia:
# - t3.medium:  2 vCPU,  4Gi RAM  (~$30/mes)
# - t3.large:   2 vCPU,  8Gi RAM  (~$60/mes)
# - t3.xlarge:  4 vCPU, 16Gi RAM  (~$120/mes)
# - m5.large:   2 vCPU,  8Gi RAM  (~$70/mes)
# - m5.xlarge:  4 vCPU, 16Gi RAM  (~$140/mes)
#
# Recomendaciones por Ambiente:
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ Ambiente â”‚ CPU LÃ­mite  â”‚ Memory LÃ­miteâ”‚ Instancias Aprox â”‚ Costo/mes Aprox â”‚
# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
# â”‚ DEV      â”‚ 16          â”‚ 64Gi         â”‚ 4-8 t3.large     â”‚ $200-400        â”‚
# â”‚ STG      â”‚ 32          â”‚ 128Gi        â”‚ 8-16 t3.large    â”‚ $500-1000       â”‚
# â”‚ UAT      â”‚ 64          â”‚ 256Gi        â”‚ 16-32 t3.large   â”‚ $1000-2000      â”‚
# â”‚ PRD      â”‚ 128         â”‚ 512Gi        â”‚ 32-64 m5.large   â”‚ $2000-4500      â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# VALORES ACTUALES (MUY ALTOS - REVISAR):
export CPU_LIMIT="16"        # Reducido de 1000 a 16 (mÃ¡s realista para DEV)
export MEMORY_LIMIT="64Gi"   # Reducido de 1000Gi a 64Gi (mÃ¡s realista para DEV)

# -----------------------------------------------------------------------------
# ğŸ—ï¸ CONFIGURACIÃ“N BÃSICA DEL CLUSTER (OBLIGATORIAS)
# -----------------------------------------------------------------------------

# Nombre del cluster EKS donde se instalarÃ¡n los controladores
# Ejemplo: "mi-cluster-produccion", "dev-cluster"
#export CLUSTER_NAME="ban-xrs-karpenter-eks-cluster-poc"
export CLUSTER_NAME="ban-xrs-karpenter-eks-cluster-poc"

# RegiÃ³n AWS donde estÃ¡ ubicado el cluster EKS
# Ejemplos: "us-east-1", "us-west-2", "eu-west-1"
export AWS_REGION="us-east-1"

# ID de la cuenta AWS (12 dÃ­gitos)
# Se usa para crear polÃ­ticas IAM y roles
# Obtener con: aws sts get-caller-identity --query Account --output text
#export AWS_ACCOUNT_ID="161156235207"
export AWS_ACCOUNT_ID="161156235207"

# ID de la VPC donde estÃ¡ el cluster EKS
# Se usa para buscar subnets y security groups automÃ¡ticamente
# Obtener con: aws eks describe-cluster --name CLUSTER_NAME --query cluster.resourcesVpcConfig.vpcId
#export VPC_ID="vpc-0c75a54998a50fe08"
export VPC_ID="vpc-0c75a54998a50fe08"

# -----------------------------------------------------------------------------
# ğŸŒ CONFIGURACIÃ“N DE RED
# -----------------------------------------------------------------------------

# Subnets pÃºblicas (separadas por comas)
# OPCIONAL: Dejar vacÃ­o para selecciÃ³n automÃ¡tica
# Usar para Load Balancers internet-facing
# Ejemplo: "subnet-abc123,subnet-def456"
#export PUBLIC_SUBNETS="subnet-05d84f7334351707d,subnet-0f3f227bf490bb731"
export PUBLIC_SUBNETS="subnet-05d84f7334351707d,subnet-0f3f227bf490bb731"

# Subnets privadas (separadas por comas)
# OPCIONAL: Dejar vacÃ­o para selecciÃ³n automÃ¡tica
# Usar para Load Balancers internos
# Ejemplo: "subnet-ghi789,subnet-jkl012"
export PRIVATE_SUBNETS=""

# Tipo de subnets a usar para el Load Balancer
# VALORES: "public" (internet-facing) o "private" (internal)
# - public: Load Balancer accesible desde internet
# - private: Load Balancer solo accesible desde la VPC
export SUBNET_TYPE="public"

# Security Group personalizado para el Load Balancer
# OPCIONAL: Se combinarÃ¡ automÃ¡ticamente con el security group del cluster EKS
# El script busca automÃ¡ticamente el security group del cluster
# Ejemplo: "sg-0a1b2c3d4e5f6g7h8"
#export INGRESS_SECURITY_GROUP="sg-0dfffe8a742937f9b"
export INGRESS_SECURITY_GROUP="sg-0dfffe8a742937f9b"

# -----------------------------------------------------------------------------
# ğŸ” CONFIGURACIÃ“N DE SEGURIDAD Y CERTIFICADOS
# -----------------------------------------------------------------------------

# Certificado SSL/TLS de AWS Certificate Manager
# OPCIONAL: Dejar vacÃ­o para usar solo HTTP
# ARN completo del certificado ACM
# Ejemplo: "arn:aws:acm:us-east-1:123456789012:certificate/12345678-1234-1234-1234-123456789012"
# Obtener con: aws acm list-certificates --region REGION
export ACM_CERTIFICATE_ARN="arn:aws:acm:us-east-1:161156235207:certificate/52c0070b-22d1-4b13-b3d2-435dad532913"

# -----------------------------------------------------------------------------
# âš™ï¸ CONFIGURACIÃ“N DEL AWS LOAD BALANCER CONTROLLER
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# ğŸ·ï¸ CONFIGURACIÃ“N DE TAGS PARA INSTANCIAS EC2
# -----------------------------------------------------------------------------

# Tags empresariales para instancias EC2 (se aplican en NodeClass)
export TAG_COST_CENTER="HN00000000"
export TAG_TRIBU="Infrastructure"
export TAG_SQUAD="Platform"
export TAG_BACKUP="false"
export TAG_COUNTRY="hnd"
export TAG_APPLICATION_NAME="risk-compliance"
export TAG_COMPANY="ban"
export TAG_DISASTER_RECOVERY="low"
export TAG_BIA="false"
export TAG_CONFIDENTIALITY="internal"
export TAG_INTEGRITY="low"
export TAG_AVAILABILITY="low"
export TAG_PCI="false"
export TAG_ENVIRONMENT="dev"
export TAG_MAP_MIGRATED="map-ficohsa"
export TAG_TFMODULE="eks-auto-mode"
export TAG_SCHEDULE="Honduras"
export TAG_PERSONAL_DATA="false"

# -----------------------------------------------------------------------------
# âš™ï¸ CONFIGURACIÃ“N DEL AWS LOAD BALANCER CONTROLLER
# -----------------------------------------------------------------------------

# Crear IAM Role automÃ¡ticamente para AWS LB Controller
# VALORES: "true" o "false"
# Si es "false", debe existir el role: AmazonEKSLoadBalancerControllerRole
export CREATE_IAM_ROLE="true"

# Crear IAM Policy automÃ¡ticamente
# VALORES: "true" o "false"  
# Si es "false", debe existir la policy: AWSLoadBalancerControllerIAMPolicy
export CREATE_IAM_POLICY="true"

# Crear Service Account automÃ¡ticamente
# VALORES: "true" o "false"
# Si es "false", debe existir: aws-load-balancer-controller en kube-system
export CREATE_SERVICE_ACCOUNT="true"

# VersiÃ³n del AWS Load Balancer Controller
# Usar versiÃ³n especÃ­fica para entornos de producciÃ³n (buena prÃ¡ctica)
# Verificar versiones en: https://github.com/kubernetes-sigs/aws-load-balancer-controller/releases
# NOTA: Esta es la versiÃ³n del CHART de Helm, no la versiÃ³n de la aplicaciÃ³n
export AWS_LB_CONTROLLER_VERSION="1.14.1"

# -----------------------------------------------------------------------------
# ğŸš€ CONFIGURACIÃ“N DEL NGINX INGRESS CONTROLLER
# -----------------------------------------------------------------------------

# Namespace donde se instalarÃ¡ NGINX Ingress Controller
# Se crearÃ¡ automÃ¡ticamente si no existe
# Recomendado: "ingress-nginx" (estÃ¡ndar) o nombre personalizado, no colocar kube-system
export NGINX_NAMESPACE="ban-xrs-karpenter-ns"

# Nombre del Network Load Balancer que crearÃ¡ NGINX
# Debe ser Ãºnico en tu cuenta AWS
# MÃ¡ximo 32 caracteres, solo letras, nÃºmeros y guiones
#export NLB_NAME="balanceador-nginx-nlb"
export NLB_NAME="ban-xrs-karpenter-nlb"

# Tipo de target para el Load Balancer
# VALORES: "ip" o "instance"
# - ip: Recomendado para Fargate y mejor rendimiento
# - instance: Para nodos EC2 tradicionales
export TARGET_TYPE="ip"

# VersiÃ³n del NGINX Ingress Controller
# Usar versiÃ³n especÃ­fica para entornos de producciÃ³n
# Verificar versiones en: https://github.com/kubernetes/ingress-nginx/releases
export NGINX_CONTROLLER_VERSION="4.13.3"

# =============================================================================
# ğŸ“‹ NOTAS IMPORTANTES Y COMANDOS ÃšTILES
# =============================================================================
# 
# ğŸ”’ SEGURIDAD:
#    - Los security groups se combinan automÃ¡ticamente
#    - Se crean roles IAM con permisos mÃ­nimos necesarios
#    - Los certificados ACM proporcionan cifrado TLS
#
# ğŸ’° COSTOS:
#    - Network Load Balancer: ~$16-45/mes
#    - Application Load Balancer: ~$16-22/mes  
#    - Data Processing: $0.006-0.008 por GB
#    - t3.xlarge: ~$0.1664/hora (~$120/mes por nodo)

#
# ğŸ“Š LÃMITES AWS:
#    - MÃ¡ximo 50 Load Balancers por regiÃ³n
#    - MÃ¡ximo 1000 Target Groups por regiÃ³n
#    - Verificar lÃ­mites en AWS Service Quotas
#
# ğŸ”§ TROUBLESHOOTING:
#    - Ejecutar ./verify-installation.sh para diagnÃ³sticos
#    - Revisar logs: kubectl logs -n kube-system deployment/aws-load-balancer-controller
#    - Verificar eventos: kubectl get events --sort-by='.lastTimestamp'
#
# ğŸ’¡ COMANDOS ÃšTILES:
#    - Obtener Account ID: aws sts get-caller-identity --query Account --output text
#    - Obtener VPC ID: aws eks describe-cluster --name CLUSTER_NAME --query cluster.resourcesVpcConfig.vpcId
#    - Listar subnets: aws ec2 describe-subnets --filters "Name=vpc-id,Values=VPC_ID" --query 'Subnets[*].[SubnetId,AvailabilityZone,MapPublicIpOnLaunch]'
#    - Listar certificados: aws acm list-certificates --region REGION
#    - Verificar perfiles: aws configure list-profiles
#
# =============================================================================
